{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "ee556216",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient of f(x,y) at (1, -2) is  [  6. -32.]\n",
      "Value of f(x,y) at (1,-2) 19\n"
     ]
    }
   ],
   "source": [
    "import numdifftools as nd\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def f_val(xarr): \n",
    "    return 3*((xarr[0])**2) +(xarr[1])**4\n",
    "grad2 = nd.Gradient(f_val)([1,-2])\n",
    "print(\"Gradient of f(x,y) at (1, -2) is \", grad2)\n",
    "print(\"Value of f(x,y) at (1,-2)\",f_val([1,-2]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "992b3170",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backtracking_line_search(x,delta_x,grad):\n",
    "    t=1\n",
    "    c=[(x[0]+(t*(delta_x[0]))),(x[1]+(t*(delta_x[1])))]\n",
    "    a=f_val(c)\n",
    "    b=f_val(x)+alpha*t*(np.dot(grad.T,delta_x))\n",
    "    #print(a,b)\n",
    "    while a>b:\n",
    "        t=beta*t\n",
    "        c=[(x[0]+(t*(delta_x[0]))),(x[1]+(t*(delta_x[1])))]\n",
    "        a=f_val(c)\n",
    "        b=f_val(x)+alpha*t*(np.dot(grad.T,delta_x))\n",
    "    return t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "aa2055e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step size for 1st iteration:  0.0625\n",
      "(x,y) after 1 iteration of gradient descent:  [ 6.2500000e-01 -4.4408921e-16]\n",
      "Value of f(x,y) at (x,y) after 1st iteration:  1.1718750000000004\n"
     ]
    }
   ],
   "source": [
    "#Question: 1(a)\n",
    "x=[1,-2]\n",
    "alpha=0.1\n",
    "beta=0.5\n",
    "gradient=nd.Gradient(f_val)(x)\n",
    "#print(\"grad\",grad)\n",
    "delta_x_val=-1*gradient\n",
    "#print(\"delta_x\",delta_x)\n",
    "step_size=backtracking_line_search(x,delta_x_val,gradient)\n",
    "print(\"Step size for 1st iteration: \",step_size)\n",
    "x=x+step_size*delta_x\n",
    "print(\"(x,y) after 1 iteration of gradient descent: \",x)\n",
    "print(\"Value of f(x,y) at (x,y) after 1st iteration: \",f_val(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "feba7fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step size for 1st iteration:  0.1\n",
      "(x,y) after 1 iteration of gradient descent:  [0.4 1.2]\n",
      "Value of f(x,y) at (x,y) after 1st iteration:  2.5535999999999954\n"
     ]
    }
   ],
   "source": [
    "#Question: 1(b)\n",
    "x=[1,-2]\n",
    "alpha=0.1\n",
    "beta=0.1\n",
    "gradient=nd.Gradient(f_val)(x)\n",
    "#print(\"grad\",grad)\n",
    "delta_x_val=-1*gradient\n",
    "#print(\"delta_x\",delta_x)\n",
    "step_size=backtracking_line_search(x,delta_x_val,gradient)\n",
    "print(\"Step size for 1st iteration: \",step_size)\n",
    "x=x+step_size*delta_x\n",
    "print(\"(x,y) after 1 iteration of gradient descent: \",x)\n",
    "print(\"Value of f(x,y) at (x,y) after 1st iteration: \",f_val(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "a52d6dd8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step size for 1st iteration:  1\n",
      "(x,y) after 1 iteration of Newton descent:  [ 1.22124533e-15 -1.33333333e+00]\n",
      "Value of f(x,y) at (x,y) after 1st iteration:  3.1604938271604994\n"
     ]
    }
   ],
   "source": [
    "#Question: 1(c)\n",
    "x=[1,-2]\n",
    "alpha=0.1\n",
    "beta=0.5\n",
    "gradient=nd.Gradient(f_val)(x)\n",
    "hess=nd.Hessian(f_val)(x)\n",
    "hess_inv=np.linalg.inv(hess)\n",
    "#print(hess,hess_inv)\n",
    "delta_xnt=-1*np.dot(hess_inv,gradient)\n",
    "lamda_sq=np.dot(gradient.T,np.dot(hess_inv,gradient))\n",
    "step_size=backtracking_line_search(x,delta_xnt,gradient)\n",
    "print(\"Step size for 1st iteration: \",step_size)\n",
    "x=x+step_size*delta_xnt\n",
    "print(\"(x,y) after 1 iteration of Newton descent: \",x)\n",
    "print(\"Value of f(x,y) at (x,y) after 1st iteration: \",f_val(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "9823e729",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Iterations:  11911\n",
      "(x,y): [1.26277935e-07 5.45734389e-03]\n",
      "f-value after 11911 iterations 8.870512416299556e-10\n"
     ]
    }
   ],
   "source": [
    "#Question: 1(d) --Gradient Descent\n",
    "import math\n",
    "x=[1,-2]\n",
    "alpha=0.1\n",
    "beta=0.7\n",
    "epsilon=1e-3\n",
    "iteration=0\n",
    "while True:\n",
    "    gradient=nd.Gradient(f_val)(x)\n",
    "    delta_x_val=-1*gradient\n",
    "    #print(np.linalg.norm(gradient,2))\n",
    "    if(np.linalg.norm(gradient,2)<=1e-6):\n",
    "        break\n",
    "    iteration=iteration+1\n",
    "    step_size=backtracking_line_search(x,delta_x_val,gradient)\n",
    "    x=x+step_size*delta_x_val\n",
    "    #print(\"Iteration-\",iteration,\"(x,y):\",x,\"f-value\",f_val(x))\n",
    "print(\"Total Iterations: \",iteration)\n",
    "print(\"(x,y):\",x)\n",
    "print(\"f-value after\",iteration,\"iterations\",f_val(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "f3b367f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Iterations:  6\n",
      "(x,y): [ 0.         -0.17558299]\n",
      "f-value after 6 iterations 0.0009504510730167913\n"
     ]
    }
   ],
   "source": [
    "#Question: 1(d) --Newton Descent\n",
    "x=[1,-2]\n",
    "alpha=0.1\n",
    "beta=0.7\n",
    "epsilon=0.001\n",
    "iteration=0\n",
    "while True:\n",
    "    gradient=nd.Gradient(f_val)(x)\n",
    "    hess=nd.Hessian(f_val)(x)\n",
    "    hess_inv=np.linalg.inv(hess)\n",
    "    #print(hess,hess_inv)\n",
    "    delta_xnt=-1*np.dot(hess_inv,gradient)\n",
    "    lamda_sq=np.dot(gradient.T,np.dot(hess_inv,gradient))\n",
    "    if(lamda_sq*0.5<epsilon):\n",
    "        break\n",
    "    iteration=iteration+1\n",
    "    step_size=backtracking_line_search(x,delta_xnt,gradient)\n",
    "    x=x+step_size*delta_xnt\n",
    "    #print(x,f_val(x))\n",
    "print(\"Total Iterations: \",iteration)\n",
    "print(\"(x,y):\",x)\n",
    "print(\"f-value after\",iteration,\"iterations\",f_val(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "318ecb8f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
